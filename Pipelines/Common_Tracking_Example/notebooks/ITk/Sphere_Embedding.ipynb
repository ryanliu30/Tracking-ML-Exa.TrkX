{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Metric Learning in Embedded Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System imports\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "\n",
    "# External imports\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import auc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch import nn\n",
    "from pytorch_lightning.loggers import TensorBoardLogger, WandbLogger\n",
    "from pytorch_lightning import Trainer\n",
    "import frnn\n",
    "\n",
    "sys.path.append('../..')\n",
    "\n",
    "from LightningModules.Embedding.Models.sphere_layerless_embedding import SphereLayerlessEmbedding\n",
    "import copy\n",
    "from LightningModules.Embedding.utils import multi_build_edges, graph_intersection\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "import wandb\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Lightning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example notebook, we will use an approach to ML called Pytorch Lightning. Pytorch is a library like Tensorflow, which is very popular in ML engineering. It's main appeal is foolproof tracking of gradients for backpropagation, and very easy manipulation of tensors on and off GPUs. \n",
    "\n",
    "Pytorch Lightning is an extension of Pytorch that makes some decisions about the best-practices for training. Instead of you writing the training loop yourself, and moving things on and off a GPU, it handles much of this for you. You write all the data loading logic, the loss functions, etc. into a `LightningModule` and then hand this module to a `Trainer`. Together, the module and trainer are the two objects that allow training and inference. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we start by importing a class that we have written ourselves, in this case a LightningModule that is in charge of loading TrackML (Codalab) data, and training and validating an embedding/metric learning model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct PyLightning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An ML model typically has many knobs to turn, as well as locations of data, some training preferences, and so on. For convenience, let's put all of these parameters into a YAML file and load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Sphere_embedding_sweep.yaml\") as f:\n",
    "        sweep_hparams = yaml.load(f, Loader=yaml.FullLoader)\n",
    "with open(\"Sphere_embedding_defaults.yaml\") as f:\n",
    "        default_hparams = yaml.load(f, Loader=yaml.FullLoader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_configuration = {\n",
    "    \"name\": run_name,\n",
    "    \"project\": \"ITk_full\",\n",
    "    \"metric\": {\"name\": \"eff\", \"goal\": \"maximize\"},\n",
    "    \"method\": \"grid\",\n",
    "    \"parameters\": sweep_hparams\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_training():\n",
    "    \n",
    "    model = SphereLayerlessEmbedding({**default_hparams})\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor='eff',\n",
    "        mode=\"max\",\n",
    "        save_top_k=2,\n",
    "        save_last=True)\n",
    "\n",
    "    logger = WandbLogger()\n",
    "    trainer = Trainer(gpus=1, max_steps=default_hparams[\"max_steps\"], logger=logger, val_check_interval = 0.5, num_sanity_val_steps=2, callbacks=[checkpoint_callback], default_root_dir=\"/global/cfs/cdirs/m3443/usr/ryanliu/ITk_embedding/\")\n",
    "    trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally! Let's train! We instantiate a `Trainer` class that knows things like which hardware to work with, how long to train for, and a **bunch** of default options that we ignore here. Check out the Trainer class docs in Pytorch Lightning. Suffice it to say that it clears away much repetitive boilerplate in training code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training():\n",
    "    wandb.init()\n",
    "    model = SphereLayerlessEmbedding({**default_hparams, **wandb.config})\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor='eff',\n",
    "        mode=\"max\",\n",
    "        save_top_k=2,\n",
    "        save_last=True)\n",
    "\n",
    "    logger = WandbLogger()\n",
    "    trainer = Trainer(gpus=1, max_steps=default_hparams[\"max_steps\"], val_check_interval = 1000, logger=logger, num_sanity_val_steps=2, callbacks=[checkpoint_callback], default_root_dir=\"/global/cfs/cdirs/m3443/usr/ryanliu/ITk_embedding/\")\n",
    "    trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep_configuration, project = \"ITk_full\")\n",
    "\n",
    "# run the sweep\n",
    "wandb.agent(sweep_id, function=training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Build Edge Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"/global/cfs/cdirs/m3443/usr/ryanliu/ITk_embedding/ITk_full/nbse7ida/checkpoints/epoch=1-step=7999.ckpt\"\n",
    "checkpoint = torch.load(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SphereLayerlessEmbedding.load_from_checkpoint(checkpoint_path).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.69 ms, sys: 4.78 ms, total: 14.5 ms\n",
      "Wall time: 13.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.setup(stage=\"fit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Building Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class EmbeddingInferenceBuilder:\n",
    "    def __init__(self, model, output_dir, overwrite=False):\n",
    "        self.output_dir = output_dir\n",
    "        self.model = model\n",
    "        self.overwrite = overwrite\n",
    "\n",
    "        # Prep the directory to produce inference data to\n",
    "        self.datatypes = [\"train\", \"val\", \"test\"]\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "        [\n",
    "            os.makedirs(os.path.join(self.output_dir, datatype), exist_ok=True)\n",
    "            for datatype in self.datatypes\n",
    "        ]\n",
    "\n",
    "\n",
    "    def build(self):\n",
    "        print(\"Training finished, running inference to build graphs...\")\n",
    "\n",
    "        # By default, the set of examples propagated through the pipeline will be train+val+test set\n",
    "        datasets = {\n",
    "            \"test\": self.model.testset,\n",
    "            \"val\": self.model.valset,\n",
    "            \"train\": self.model.trainset,\n",
    "        }\n",
    "        total_length = sum([len(dataset) for dataset in datasets.values()])\n",
    "        batch_incr = 0\n",
    "        eff = 0\n",
    "        pur = 0\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for set_idx, (datatype, dataset) in enumerate(datasets.items()):\n",
    "                for batch_idx, batch in enumerate(dataset):\n",
    "                    percent = (batch_incr / total_length) * 100\n",
    "                    sys.stdout.flush()\n",
    "                    sys.stdout.write(f\"{percent:.01f}% inference complete, eff: {eff:.01f}%, pur: {pur:.02f}%\\r\")\n",
    "                    if (\n",
    "                        not os.path.exists(\n",
    "                            os.path.join(\n",
    "                                self.output_dir, datatype, batch.event_file[-5:]\n",
    "                            )\n",
    "                        )\n",
    "                    ) or self.overwrite:\n",
    "                        batch_to_save = copy.deepcopy(batch)\n",
    "                        batch_to_save = batch_to_save.to(\n",
    "                            self.model.device\n",
    "                        )\n",
    "                        eff, pur = self.construct_downstream(batch_to_save, datatype)\n",
    "\n",
    "                    batch_incr += 1\n",
    "\n",
    "    def construct_downstream(self, batch, datatype):\n",
    "\n",
    "        if \"ci\" in self.model.hparams[\"regime\"]:\n",
    "            input_data = torch.cat([batch.cell_data[:, :self.model.hparams[\"cell_channels\"]], batch.x], axis=-1)\n",
    "            spatials = self.model(input_data)\n",
    "        else:\n",
    "            input_data = batch.x\n",
    "            input_data[input_data != input_data] = 0\n",
    "            spatials = self.model(input_data)\n",
    "        \n",
    "        if self.model.hparams[\"normalize\"]:\n",
    "            spatials = nn.functional.normalize(spatials, p=2.0, dim=2, eps=1e-12)\n",
    "\n",
    "        # Make truth bidirectional\n",
    "        e_bidir = torch.cat(\n",
    "            [batch[\"modulewise_true_edges\"],\n",
    "             batch[\"modulewise_true_edges\"].flip(0)], axis=-1\n",
    "        )\n",
    "\n",
    "        # Build the radius graph with radius < r_test\n",
    "        e_spatial = multi_build_edges(\n",
    "            spatials, spatials, indices=None, r_max=self.model.hparams[\"r_test\"], k_max =1000\n",
    "        ).long()  # This step should remove reliance on r_val, and instead compute an r_build based on the EXACT r required to reach target eff/pur\n",
    "\n",
    "        # Arbitrary ordering to remove half of the duplicate edges\n",
    "        R_dist = torch.sqrt(batch.x[:, 0] ** 2 + batch.x[:, 2] ** 2)\n",
    "        e_spatial = e_spatial[:, (R_dist[e_spatial[0]] <= R_dist[e_spatial[1]])]\n",
    "\n",
    "        e_spatial_easy_fake = e_spatial[:, batch.pid[e_spatial[0]] != batch.pid[e_spatial[1]]]\n",
    "        y_cluster_easy_fake = torch.zeros(e_spatial_easy_fake.shape[1])\n",
    "        \n",
    "        e_spatial_ambiguous = e_spatial[:, batch.pid[e_spatial[0]] == batch.pid[e_spatial[1]]]\n",
    "        e_spatial_ambiguous, y_cluster_ambiguous = graph_intersection(e_spatial_ambiguous, e_bidir)\n",
    "        \n",
    "        e_spatial = torch.cat([e_spatial_easy_fake.cpu(), e_spatial_ambiguous], dim=-1)\n",
    "        y_cluster = torch.cat([y_cluster_easy_fake, y_cluster_ambiguous])\n",
    "        \n",
    "        eff = (2*y_cluster.sum()/e_bidir.shape[1]).item()*100\n",
    "        pur = (y_cluster.sum()/y_cluster.shape[0]).item()*100\n",
    "        \n",
    "        # e_spatial, y_cluster = graph_intersection(e_spatial, e_bidir)\n",
    "\n",
    "        # Re-introduce random direction, to avoid training bias\n",
    "        random_flip = torch.randint(2, (e_spatial.shape[1],)).bool()\n",
    "        e_spatial[0, random_flip], e_spatial[1, random_flip] = (\n",
    "            e_spatial[1, random_flip],\n",
    "            e_spatial[0, random_flip],\n",
    "        )\n",
    "        e_spatial = e_spatial[:, torch.randperm(e_spatial.shape[1])]\n",
    "        \n",
    "\n",
    "        batch.edge_index = e_spatial\n",
    "        batch.y = y_cluster\n",
    "\n",
    "        self.save_downstream(batch, datatype)\n",
    "        \n",
    "        return eff, pur\n",
    "\n",
    "    def save_downstream(self, batch, datatype):\n",
    "\n",
    "        with open(\n",
    "            os.path.join(self.output_dir, datatype, batch.event_file[-5:]), \"wb\"\n",
    "        ) as pickle_file:\n",
    "            torch.save(batch, pickle_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/global/cfs/cdirs/m3443/usr/ryanliu/ITk_embedding/ITk_processed/ITk_full\"\n",
    "model.hparams[\"r_test\"] = 1.0\n",
    "edge_builder = EmbeddingInferenceBuilder(model, output_dir, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished, running inference to build graphs...\n",
      "0.9% inference complete, eff: 94.8%, pur: 0.06%\r"
     ]
    }
   ],
   "source": [
    "edge_builder.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Gnn",
   "language": "python",
   "name": "gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
