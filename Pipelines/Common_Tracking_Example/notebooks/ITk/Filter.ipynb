{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Filtering Embedded Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System imports\n",
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "\n",
    "# External imports\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import auc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from pytorch_lightning.loggers import TensorBoardLogger, WandbLogger\n",
    "from pytorch_lightning import Trainer\n",
    "import wandb\n",
    "\n",
    "sys.path.append('../..')\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "from LightningModules.Filter.Models.pyramid_filter import PyramidFilter\n",
    "from LightningModules.Filter.utils import graph_intersection\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Lightning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct PyLightning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An ML model typically has many knobs to turn, as well as locations of data, some training preferences, and so on. For convenience, let's put all of these parameters into a YAML file and load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"filter-sweep.yaml\") as f:\n",
    "        sweep_hparams = yaml.load(f, Loader=yaml.FullLoader)\n",
    "with open(\"filter.yaml\") as f:\n",
    "        default_hparams = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_configuration = {\n",
    "    \"name\": run_name,\n",
    "    \"project\": \"ITk_barrel_full_filter\",\n",
    "    \"metric\": {\"name\": \"pur\", \"goal\": \"maximize\"},\n",
    "    \"method\": \"grid\",\n",
    "    \"parameters\": sweep_hparams\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training():\n",
    "    wandb.init()\n",
    "    model = PyramidFilter({**default_hparams, **wandb.config})\n",
    "\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor='pur',\n",
    "        mode=\"max\",\n",
    "        save_top_k=2,\n",
    "        save_last=True)\n",
    "\n",
    "    logger = WandbLogger()\n",
    "    trainer = Trainer(gpus=1, max_steps=default_hparams[\"max_steps\"], val_check_interval = 1000, logger=logger, callbacks=[checkpoint_callback], default_root_dir=\"/global/cfs/cdirs/m3443/usr/ryanliu/ITk_filter/\")\n",
    "    trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep_configuration, project = \"ITk_barrel_full_filter\")\n",
    "\n",
    "# run the sweep\n",
    "wandb.agent(sweep_id, function=training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Metric Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally! Let's train! We instantiate a `Trainer` class that knows things like which hardware to work with, how long to train for, and a **bunch** of default options that we ignore here. Check out the Trainer class docs in Pytorch Lightning. Suffice it to say that it clears away much repetitive boilerplate in training code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='eff',\n",
    "    mode=\"max\",\n",
    "    save_top_k=2,\n",
    "    save_last=True)\n",
    "\n",
    "model = PyramidFilter({**default_hparams})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# logger = WandbLogger(project=\"ITk_0GeV_Filter\")\n",
    "trainer = Trainer(gpus=1, max_epochs=default_hparams[\"max_epochs\"], num_sanity_val_steps=2, logger=None, callbacks=[checkpoint_callback])\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"/global/cfs/cdirs/m3443/usr/ryanliu/ITk_filter/ITk_barrel_full_filter/clzmphv8/checkpoints/last.ckpt\"\n",
    "checkpoint = torch.load(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PyramidFilter.load_from_checkpoint(checkpoint_path).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.89 ms, sys: 4.75 ms, total: 9.64 ms\n",
      "Wall time: 55.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.setup(stage=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "class FilterInferenceBuilder:\n",
    "    def __init__(self, model, output_dir, overwrite=False):\n",
    "        self.output_dir = output_dir\n",
    "        self.model = model\n",
    "        self.overwrite = overwrite\n",
    "\n",
    "        # Prep the directory to produce inference data to\n",
    "        self.datatypes = [\"test\", \"val\", \"train\"]\n",
    "        os.makedirs(self.output_dir, exist_ok=True)\n",
    "        [\n",
    "            os.makedirs(os.path.join(self.output_dir, datatype), exist_ok=True)\n",
    "            for datatype in self.datatypes\n",
    "        ]\n",
    "\n",
    "\n",
    "    def build(self):\n",
    "        print(\"Training finished, running inference to build graphs...\")\n",
    "\n",
    "        # By default, the set of examples propagated through the pipeline will be train+val+test set\n",
    "        datasets = {\n",
    "            # \"test\": self.model.testset,\n",
    "            \"val\": self.model.valset,\n",
    "            # \"train\": self.model.trainset,\n",
    "        }\n",
    "        total_length = sum([len(dataset) for dataset in datasets.values()])\n",
    "        batch_incr = 0\n",
    "        eff = 0\n",
    "        pur = 0\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for set_idx, (datatype, dataset) in enumerate(datasets.items()):\n",
    "                for batch_idx, batch in enumerate(dataset):\n",
    "                    \n",
    "                    batch = torch.load(batch, map_location=torch.device(\"cpu\"))\n",
    "                    percent = (batch_incr / total_length) * 100\n",
    "                    sys.stdout.flush()\n",
    "                    sys.stdout.write(f\"{percent:.01f}% inference complete, eff: {eff:.02f}%, pur: {pur:.03f}%\\r\")\n",
    "                    if (\n",
    "                        not os.path.exists(\n",
    "                            os.path.join(\n",
    "                                self.output_dir, datatype, batch.event_file[-5:]\n",
    "                            )\n",
    "                        )\n",
    "                    ) or self.overwrite:\n",
    "                        batch_to_save = copy.deepcopy(batch)\n",
    "                        batch_to_save = batch_to_save.to(\n",
    "                            self.model.device\n",
    "                        )\n",
    "                        eff, pur = self.construct_downstream(batch_to_save, datatype)\n",
    "\n",
    "                    batch_incr += 1\n",
    "\n",
    "    def construct_downstream(self, batch, datatype):\n",
    "\n",
    "        score_list = []\n",
    "        chunks = torch.chunk(batch.idxs, self.model.hparams[\"n_chunks\"], dim = 1)\n",
    "        input_data = self.model.get_input_data(batch)\n",
    "        e_bidir = torch.cat(\n",
    "            [batch.modulewise_true_edges, batch.modulewise_true_edges.flip(0)], axis=-1\n",
    "        )\n",
    "        all_edges = torch.empty([2, 0], dtype=torch.int64).cpu()\n",
    "        all_y = torch.empty([0], dtype=torch.int64).cpu()\n",
    "        all_scores = torch.empty([0], dtype=torch.float).cpu()\n",
    "        \n",
    "        for chunk in chunks:\n",
    "\n",
    "            scores = torch.zeros(chunk.shape).to(self.model.device)\n",
    "            ind = torch.Tensor.repeat(torch.arange(chunk.shape[0], device=self.model.device), (chunk.shape[1], 1)).T.int()\n",
    "            \n",
    "            positive_idxs = chunk >= 0\n",
    "            edges = torch.stack([ind[positive_idxs], chunk[positive_idxs]]).long()\n",
    "            \n",
    "            output = self.model(\n",
    "                    input_data,\n",
    "                    edges\n",
    "                ).squeeze()\n",
    "            scores[positive_idxs] = torch.sigmoid(output)\n",
    "            score_list.append(scores.detach().cpu())\n",
    "            \n",
    "            # compute val loss\n",
    "            truth_mask = (batch.pid[edges[0]] == batch.pid[edges[1]]) & (batch.pid[edges] != 0).all(0)\n",
    "            edges_easy_fake = edges[:,truth_mask.logical_not()].clone().detach()\n",
    "            edges_ambiguous = edges[:,truth_mask].clone().detach()\n",
    "            if edges_ambiguous.numel() != 0:\n",
    "                edges_ambiguous, y_ambiguous = graph_intersection(edges_ambiguous, e_bidir)\n",
    "                edges = torch.cat([edges_easy_fake, edges_ambiguous.to(self.model.device)], dim = 1)\n",
    "                y = torch.cat([torch.zeros(edges_easy_fake.shape[1]), y_ambiguous], dim = 0)\n",
    "            else: \n",
    "                edges = edges_easy_fake\n",
    "                y = torch.zeros(edges_easy_fake.shape[1])\n",
    "            \n",
    "            output = self.model(\n",
    "                    input_data,\n",
    "                    edges\n",
    "                ).squeeze()\n",
    "            \n",
    "            all_scores = torch.cat([all_scores, torch.sigmoid(output).cpu()], dim = 0)\n",
    "            all_edges = torch.cat([all_edges, edges.cpu()], dim = 1)\n",
    "            all_y = torch.cat([all_y, y.cpu()], dim = 0)\n",
    "            \n",
    "        score_list = torch.cat(score_list, dim = 1)\n",
    "        \n",
    "        \n",
    "        # Find Cut\n",
    "        pt_mask = (batch.pt[e_bidir] >= self.model.hparams[\"signal_pt_cut\"]).all(0)\n",
    "\n",
    "        eff_cut_score = 0.296\n",
    "        \n",
    "        cut_list = (all_scores >= eff_cut_score)\n",
    "        \n",
    "        # For efficeincy and purity, evaluate on modulewise truth.\n",
    "        modulewise_true = pt_mask.sum()\n",
    "        prediction_pt_mask = (batch.pt[all_edges] >= self.model.hparams[\"signal_pt_cut\"]).all(0)\n",
    "        modulewise_true_positive = (all_y.bool() & cut_list)[prediction_pt_mask].sum()\n",
    "        modulewise_true_positive_without_cut = (all_y.bool() & cut_list).sum()\n",
    "        modulewise_positive = cut_list.sum()\n",
    "        \n",
    "        eff = (modulewise_true_positive / modulewise_true).clone().detach()\n",
    "        pur = (modulewise_true_positive_without_cut / modulewise_positive).clone().detach()\n",
    "        \n",
    "        batch.idxs_scores = score_list.clone().detach()\n",
    "\n",
    "        self.save_downstream(batch, datatype)\n",
    "        \n",
    "        return eff, pur\n",
    "\n",
    "    def save_downstream(self, batch, datatype):\n",
    "\n",
    "        with open(\n",
    "            os.path.join(self.output_dir, datatype, batch.event_file[-5:]), \"wb\"\n",
    "        ) as pickle_file:\n",
    "            torch.save(batch, pickle_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/global/cfs/cdirs/m3443/usr/ryanliu/ITk_filter/filter_processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished, running inference to build graphs...\n",
      "80.0% inference complete, eff: 0.95%, pur: 0.022%\r"
     ]
    }
   ],
   "source": [
    "edge_builder = FilterInferenceBuilder(model, output_dir, overwrite=True)\n",
    "edge_builder.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilteringSelecting:\n",
    "    def __init__(self, input_dirs, score_cut):\n",
    "        \n",
    "        self.input_dirs = input_dirs\n",
    "        self.score_cut = score_cut\n",
    "\n",
    "    def select(self):\n",
    "        all_events = []\n",
    "        print(\"Selecting data...\")\n",
    "        for input_dir in self.input_dirs:\n",
    "            events = os.listdir(input_dir)\n",
    "            all_events.extend([os.path.join(input_dir, event) for event in events])\n",
    "\n",
    "        all_events = sorted(all_events)\n",
    "        \n",
    "        total_length = len(all_events)\n",
    "        batch_incr = 0\n",
    "        \n",
    "        for event in all_events:\n",
    "                percent = (batch_incr / total_length) * 100\n",
    "                sys.stdout.flush()\n",
    "                sys.stdout.write(f\"{percent:.01f}% select complete\\r\")\n",
    "                \n",
    "                try:\n",
    "                    batch = torch.load(event, map_location=torch.device(\"cuda\"))\n",
    "                except:\n",
    "                    batch_incr += 1\n",
    "                    continue\n",
    "                    \n",
    "                batch.idxs[batch.idxs_scores < self.score_cut] = -1\n",
    "                \n",
    "                delattr(batch, \"idxs_scores\")\n",
    "                \n",
    "                with open(\n",
    "                    event, \"wb\"\n",
    "                ) as pickle_file:\n",
    "                    torch.save(batch, pickle_file)\n",
    "\n",
    "                batch_incr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = FilteringSelecting([\"/global/cfs/cdirs/m3443/usr/ryanliu/ITk_filter/filter_processed/test\",\n",
    "                               \"/global/cfs/cdirs/m3443/usr/ryanliu/ITk_filter/filter_processed/train\"\n",
    "                              ], 0.296)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Gnn",
   "language": "python",
   "name": "gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
